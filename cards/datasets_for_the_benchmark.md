---
Author:
  - Ширяев Антон
tags:
  - dataset_для_бенчмарка
date: 2024-10-07
---

# Датасеты для бенчмарка
## Этап 2 Тестирование VLLM моделей и  отбор промптов для них

Небольшие датасеты для предварительного анализа возможностей новых **VLLM-моделей** и предварительной оценки подобранных для них промптов.

Небольшие датасеты, на них оцениваем:
* стоит ли брать **VLLM-модель** для теста в бенчмарк
* стоит ли брать **данный промпт** для извлечения нужной информации из **данного типа документа** для **данной VLLM-модели**

**Датасеты:**
* 10 документов, и вопросы по всем возможным полям для них
* хорошего разрешения (чтобы человек мол легко прочитать все с документа)
* без аугментаций

Мы хотим, чтобы у **VLLM-модели** не было трудностей с чтением информации с документа.
### Датасеты

#### 1. SNILSesx10
* [ссылка](https://disk.yandex.ru/d/fCcRgxr0kyznCw)
* 10 СНИЛСов, нашего формата для задачи VQA ([ссылка](approved_dataset_format_for_vqa.md)).
* Разрешение: 800x600
#### 2. INNx10
* [ссылка](https://disk.yandex.ru/d/hR862Z9QKwu3xQ)
* 10 ИНН, нашего формата для задачи VQA ([ссылка](approved_dataset_format_for_vqa.md)).
* Разрешение: 1220x1524

## Этап 3 Выбираем оптимальный набор промптов для каждой модели

Большие датасеты, на которых отбираем **лучшие промпты** из всех возможных вариантов для выбранной **VLLM-модели**.

Большие датасеты, на них оцениваем:
* имеющиеся наборы промптов (от **моделей-генераторов промптов**) для извлечения нужной информации из документов для каждой тестируемой в бенчмарке модели ([ссылка](selected_models_for_benchmark_evaluation.md))
* оцениваем по метрикам корректность извлекаемых данных
* отбираем лучшие промпты для каждой модели ([ссылка](selected_models_for_benchmark_evaluation.md)) из всех представленных вариантов

**Датасеты:**
* 1000 документов, и вопросы по всем возможным полям для них
* хорошего разрешения
* без аугментаций

Мы хотим, чтобы у **VLLM-модели** не было трудностей с чтением информации с документа.
Производим отбор промптов для моделей на "хорошей" статистике.

### Датасеты

#### 1. SNILSesx1000
* (пока его нет, запланирован на генерацию)
* 1000 СНИЛСов, нашего формата для задачи VQA ([ссылка](approved_dataset_format_for_vqa.md)).
* Разрешение: 800x600
#### 2. INNx1000
* (пока его нет, запланирован на генерацию)
* 1000 ИНН, нашего формата для задачи VQA ([ссылка](approved_dataset_format_for_vqa.md)).
* Разрешение: 1220x1524
## Этап 4 Исследуем работу VLLM-модели на всевозможных данных

Большие датасеты, на которых исследуем работу **VLLM-модели** с оптимально подобранным для нее набором промптов на максимально разнообразных данных.

Большие датасеты, на них оцениваем:
* работу **VLLM-модели** ([ссылка](selected_models_for_benchmark_evaluation.md)) на максимально разнообразных данных
* исследуем туда ли смотрит модель?
* правильно ли распознается текст и каких ситуациях?
* ищем слабые места и точки роста
* обсуждаем со стейкхолдером имеющиеся точки роста и пути их достижения

**Датасеты:**
* 1000 документов, и вопросы по всем возможным полям для них
* разного разрешения от hd до низкого
* со всеми аугментациями

Исследуем возможности **VLLM-модели**, знакомим ее со всеми возможными данными, создаем ей различные трудности: разрешение, аугментации и т.д.
### Датасеты

#### 1. SNILSesx1000_aug
* (пока его нет, запланирован на генерацию)
* 1000 СНИЛСов, нашего формата для задачи VQA ([ссылка](approved_dataset_format_for_vqa.md)).
* Разрешение: 800x600
* Аугментации
#### 2. INNx1000_aug
* (пока его нет, запланирован на генерацию)
* 1000 ИНН, нашего формата для задачи VQA ([ссылка](approved_dataset_format_for_vqa.md)).
* Разрешение: 1220x1524
* Аугментации